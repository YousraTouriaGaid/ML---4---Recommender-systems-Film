1) What are the necessary preprocessing steps regarding:
a) classes ?

b) categorical features ? 

c) continuous features ?

2) Confusion matrix:
a)How many patient were incorrectly diagnosed with a Heart disease (false positives) ?

b)How many patient were incorrectly diagnosed as being Healthy (false negatives)?


3) Changing the threshold:
a)What is the precision if we change the threshold to have a 0.95 recall ? 

b) How many patient were incorrectly diagnosed as being Healthy (false negatives)?



4) Choosing an overall metric:

a) If I can compute my test sample probabilities and care more about the positive class, which overall metric should I use to compare classifiers ? 

b) And if I only have the class predictions and no probabilities ?



1) Quelles sont les étapes de prétraitement nécessaires concernant :
a) les classes ?
    Vérifier l’équilibre des classes (ex : maladie vs sain).

    Si déséquilibre : utiliser oversampling, undersampling, ou SMOTE.

    Encoder les labels si nécessaire (LabelEncoder).

b) les caractéristiques catégorielles ?
    Transformer les variables non numériques :

            One-Hot Encoding --> variables nominales.

            Ordinal Encoding --> variables ordonnées.

    Gérer les valeurs manquantes (remplacement ou suppression) --> (SimpleImputer(strategy="most_frequent")).

c) les caractéristiques continues ?
    Normaliser ou standardiser (StandardScaler / MinMaxScaler).

    Gérer les valeurs extrêmes (outliers).

    Traiter les valeurs manquantes --> (SimpleImputer(strategy="mean" ou "median")).




2) Matrice de confusion :


2a) 7 patients ont été incorrectement diagnostiqués comme ayant une maladie cardiaque (faux positifs).

2b) 14 patients ont été incorrectement diagnostiqués comme étant en bonne santé (faux négatifs).




3) Changement du seuil :
a) La précision si le seuil est ajusté pour obtenir un rappel de 0,95 est d'environ 0,465.

b) Le nombre de patients incorrectement diagnostiqués comme étant en bonne santé (faux négatifs) est de 1.




4) Choix d’une métrique globale :
a) Si je peux calculer les probabilités sur mon échantillon de test et que je m’intéresse davantage à la classe positive, quelle métrique globale devrais-je utiliser pour comparer les classificateurs ?
b) Et si je ne dispose que des prédictions de classe et pas des probabilités ?


Probabilités disponibles + intérêt pour la classe positive	-->  AUC-ROC ou AUC-PR

Seulement des prédictions de classe --> F1-SCORE

Classes équilibrées --> Accuracy
